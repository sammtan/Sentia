torch>=2.2.0
einops>=0.7.0
scipy>=1.12.0
transformers>=4.40.0
datasets>=2.18.0
tokenizers>=0.19.0
tqdm>=4.66.0

# Optional: install separately if needed
# flash-attn>=2.5.0      # FlashAttention-2 (Linux/CUDA only, builds from source)
# wandb>=0.17.0          # Weights & Biases logging
